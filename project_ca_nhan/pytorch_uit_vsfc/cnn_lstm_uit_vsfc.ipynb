{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8d2ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import cuda\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60834bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('processed_train.csv').dropna()\n",
    "test_df = pd.read_csv('processed_test.csv').dropna()\n",
    "val_df = pd.read_csv('processed_dev.csv').dropna()\n",
    "combine_df = pd.concat([train_df, test_df, val_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1718487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02360233  0.62782395 -0.11770976  0.74578    -0.6986473   0.4496135\n",
      " -0.01290128 -0.55761874  0.8163744  -0.5296226  -0.21645746  0.40514842\n",
      "  0.19725057  0.1587309  -0.21678615 -0.176767    0.36918408  0.16100915\n",
      "  0.5359108  -0.15905893 -0.29934022 -0.01921103  0.11644315  0.3774891\n",
      "  0.22186467  1.3479227  -0.40699008  0.5787796  -0.04306652 -0.3846931\n",
      "  0.03471125  0.24263023  1.0618961   0.04159101  0.35302082  0.22493672\n",
      "  0.33135733 -0.38879484  0.476584    0.6932649   0.23081763  0.24549386\n",
      "  0.26727518 -0.59697276 -0.70675045  0.19075868  0.11562022 -0.09988599\n",
      "  0.16031721 -0.00994855  0.02239961  0.919814   -0.19972864 -0.6629287\n",
      "  0.54217523  0.24028456  0.11828121  0.37713417 -0.01696712  0.5403281\n",
      "  0.5920293  -0.43277305  0.30704734 -0.02188688  0.26979274 -0.7358136\n",
      "  0.40156502 -0.26405737 -0.72858936 -0.5658097  -0.4339098  -0.15935731\n",
      "  0.39170715  0.35274282 -0.08615943  0.16624998  0.4166899   0.57527596\n",
      " -0.4941464   0.24102594 -0.37186357  0.19306757  0.14365964 -0.2579873\n",
      " -0.13903621 -0.4565396  -0.35975283  0.75320137  0.03219486  0.07363355\n",
      " -0.13335894  0.83239734  1.0890194  -0.4449447   0.13991238 -0.0994364\n",
      "  0.20032802  0.22354722  0.15603872  0.00308546  0.70678025 -0.10635211\n",
      " -0.35874414 -0.09994406 -0.5138963   0.06812052 -0.45204952 -0.37340713\n",
      " -0.06193217  0.15135011 -1.1044357   0.38568208 -0.08549134  0.09622593\n",
      "  0.41809592  0.51570463 -0.21956761  0.2591121  -0.05792915  0.8109155\n",
      " -0.5371189  -0.07659639 -0.13307483 -0.15313731  0.20667933 -0.303852\n",
      " -0.18412642 -0.17064735 -0.16837882  0.3115808  -0.01407822 -0.33350125\n",
      " -0.44512373  0.68152344 -0.02608155 -0.10880856 -0.41335562 -0.19026627\n",
      " -0.7908701  -0.39321995  0.5025333   0.34767276 -0.85687673  0.98057264\n",
      " -0.6465462   0.36389968 -0.1121939  -0.51655775  0.05057698 -0.54082096\n",
      " -0.17148778  0.4500495  -0.8505725  -0.24602456 -0.05263944 -0.18228507\n",
      " -0.60612476 -0.1626232   0.11636255  0.50385773  0.15440866  0.1738659\n",
      "  0.05664894  0.13590156  0.01089484  0.51687753 -0.21526183 -0.02354334\n",
      " -0.08839292  0.69610804 -0.6429935  -0.21932092  0.43580103 -0.01660019\n",
      "  0.12601222  0.05029631 -0.31737667  1.0779725  -0.201037   -0.39125842\n",
      " -0.5851875   0.5734325   0.61617845 -0.6342849   0.19232379  0.65400785\n",
      "  0.00523799  0.20285556 -0.01449662 -0.12017562 -0.25603256 -0.44181365\n",
      " -0.22602725 -0.24728598  0.04338915 -0.47481796  0.51750046 -0.33209488\n",
      "  0.4700175   0.4132335  -0.2593109  -0.1989099   0.11603437 -0.2078682\n",
      " -0.13197224 -0.37288925  0.17494872 -0.80403006  0.525606    0.07251597\n",
      " -0.2606612  -0.0913729  -0.27998188  0.0718349  -0.30761665  0.01665132\n",
      "  0.26314935  0.07062534 -0.12731095  0.27564546  0.08272184  0.19632421\n",
      " -0.3217933   0.29169244 -0.4846546  -0.8894701  -0.17358947  0.14799118\n",
      "  0.3144092  -0.25654036  0.15373902 -0.40764114  0.7939324  -0.0833539\n",
      " -0.13004483  0.29247603 -0.02094447  0.7928289  -0.7002551  -0.16773902\n",
      " -0.15930237  0.31443033 -0.12244026  0.60852045  0.03358803 -0.08729668\n",
      "  0.33102363 -0.13635376 -0.35853818  0.4730068  -0.22247429  1.1890341\n",
      " -0.31757686  0.5636603  -0.9773075   0.5653173   0.05184056  0.6556201\n",
      " -0.14106204  0.0748959   0.5292333  -0.35258803  0.08566575 -0.5063106\n",
      "  0.39362484 -0.03645322  1.1281316  -0.3720841  -0.29823607  0.3021563\n",
      "  0.9239293  -0.39687514 -0.42457485 -0.3827931   0.12343682  0.24241807\n",
      " -0.5238795   0.6338976  -0.06542619  0.29820475  0.3379701   0.34276792\n",
      " -0.06626061  0.02512435  0.28165525  0.47917038  0.41191697  0.25273722\n",
      "  0.17373016 -0.2274241  -0.3537757  -0.22072324  0.1886637  -0.9125761\n",
      " -0.53352946  0.84436375  0.07725213  1.1167967  -0.29486057  0.58469   ]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "tokens_list_combine = [word_tokenize(text) for text in combine_df.text]\n",
    "train_text_tokens = [word_tokenize(text) for text in train_df.text]\n",
    "test_text_tokens = [word_tokenize(text) for text in test_df.text]\n",
    "val_text_tokens = [word_tokenize(text) for text in val_df.text]\n",
    "\n",
    "# Tạo tập dữ liệu huấn luyện (mỗi câu là một danh sách từ)\n",
    "sentences = [text.split() for text in combine_df.text]\n",
    "\n",
    "# Huấn luyện FastText\n",
    "fasttext = FastText(tokens_list_combine, vector_size=300, window=7, min_count=1, workers=4)\n",
    "\n",
    "# Kiểm tra vector của một từ\n",
    "print(fasttext.wv[\"học\"])  # Lấy vector của từ \"học\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053e79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data shape: torch.Size([11425, 160])\n",
      "data_vocab_size: 4094\n",
      "training sample: 11425\n",
      "validation sample: 1583\n",
      "test sample: 3166\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "tokenizer_data = Tokenizer(filters='!\"#$%&*+,-./;<=>?@[\\\\]^{|}~\\t\\n')\n",
    "tokenizer_data.fit_on_texts(tokens_list_combine)\n",
    "\n",
    "tokenized_data_text_train = tokenizer_data.texts_to_sequences(train_text_tokens)\n",
    "train_features = pad_sequences(tokenized_data_text_train, maxlen=160)\n",
    "\n",
    "tokenized_data_text_test = tokenizer_data.texts_to_sequences(test_text_tokens)\n",
    "test_features = pad_sequences(tokenized_data_text_test, maxlen=160)\n",
    "\n",
    "tokenized_data_text_val = tokenizer_data.texts_to_sequences(val_text_tokens)\n",
    "val_features = pad_sequences(tokenized_data_text_val, maxlen=160)\n",
    "\n",
    "pickle.dump(tokenizer_data, open(\"tokenizer_data.pkl\", \"wb\"))\n",
    "data_vocab_size = len(tokenizer_data.word_index)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_features = torch.tensor(train_features, dtype=torch.long)\n",
    "test_features = torch.tensor(test_features, dtype=torch.long)\n",
    "val_features = torch.tensor(val_features, dtype=torch.long)\n",
    "\n",
    "print(\"input data shape:\", train_features.shape)\n",
    "print(\"data_vocab_size:\", data_vocab_size)\n",
    "print(\"training sample:\", len(train_features))\n",
    "print(\"validation sample:\", len(val_features))\n",
    "print(\"test sample:\", len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce712995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4094 word vectors.\n",
      "Vocab size 4094\n",
      "Fasttext embedding shape: torch.Size([4094, 300])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "for w in fasttext.wv.key_to_index.keys():\n",
    "    embeddings_index[w] = fasttext.wv[w]\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "words = fasttext.wv.key_to_index.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "\n",
    "# Populate the embedding matrix\n",
    "for word, i in tokenizer_data.word_index.items():\n",
    "    if i >= data_vocab_size:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = fasttext.wv[w]\n",
    "\n",
    "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "print(f'Fasttext embedding shape: {embedding_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bee28150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_LSTM_DTHSH(nn.Module):\n",
    "    def __init__(self, embedding_dim, embedding_matrix, num_labels):\n",
    "        super(CNN_LSTM_DTHSH, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix)\n",
    "        \n",
    "        # Corrected Conv1d layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=4)  # Fixed in_channels\n",
    "        \n",
    "        # Corrected LSTM input_size\n",
    "        self.lstm1 = nn.LSTM(input_size=embedding_dim, hidden_size=128, num_layers=3, batch_first=True)\n",
    "        \n",
    "        # Corrected MultiheadAttention embed_dim\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim=128, num_heads=8, dropout=0.3, batch_first=True)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(256)  # 128 (CNN) + 128 (Attention) = 256\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embedding_dim)\n",
    "        \n",
    "        # CNN Path\n",
    "        x_cnn = x.permute(0, 2, 1)  # Shape: (batch_size, embedding_dim, seq_len)\n",
    "        x_cnn = F.relu(self.conv1(x_cnn))  # Shape: (batch_size, 128, seq_len - 2)\n",
    "        x_cnn = F.relu(self.conv2(x_cnn))  # Shape: (batch_size, 128, seq_len - 5)\n",
    "        x_cnn = torch.max(x_cnn, dim=2)[0]  # Global max pooling: (batch_size, 128)\n",
    "        \n",
    "        # LSTM + Attention Path\n",
    "        x_lstm, _ = self.lstm1(x)  # Output shape: (batch_size, seq_len, 128)\n",
    "        x_att, _ = self.multihead_attn(x_lstm, x_lstm, x_lstm)  # Output shape: (batch_size, seq_len, 128)\n",
    "        x_att = torch.mean(x_att, dim=1)  # Corrected mean: (batch_size, 128)\n",
    "        \n",
    "        # Combine CNN and Attention outputs\n",
    "        x_combined = torch.cat((x_cnn, x_att), dim=1)  # Shape: (batch_size, 256)\n",
    "        x_combined = self.layer_norm(x_combined)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x_combined = F.relu(self.fc1(x_combined))\n",
    "        x_combined = F.relu(self.fc2(x_combined))\n",
    "        outputs = self.fc3(x_combined)  # No softmax here if using nn.CrossEntropyLoss\n",
    "        return outputs       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
