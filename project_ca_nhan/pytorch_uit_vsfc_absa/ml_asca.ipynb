{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã đọc 15519 câu từ file JSON.\n",
      "------------------------------\n",
      "Tổng số mẫu: 15519\n",
      "Kích thước tập huấn luyện: 12415\n",
      "Kích thước tập kiểm thử: 3104\n",
      "------------------------------\n",
      "\n",
      "==================== Tác vụ 1: Aspect Category Detection (ACD) ====================\n",
      "Số lượng Category duy nhất: 8\n",
      "\n",
      "--- Bắt đầu ACD ---\n",
      "  Bắt đầu huấn luyện...\n",
      "  Huấn luyện hoàn tất.\n",
      "  Bắt đầu dự đoán...\n",
      "  Dự đoán hoàn tất.\n",
      "\n",
      "  --- Kết quả đánh giá ---\n",
      "  Hamming Loss: 0.1089\n",
      "  Subset Accuracy: 0.4501\n",
      "\n",
      "  Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "         Course information     0.4978    0.6799    0.5747       328\n",
      "             General review     0.2922    0.4623    0.3581       292\n",
      "       Learning environment     0.8125    0.7944    0.8034       180\n",
      "Organization and management     0.5552    0.6598    0.6030       244\n",
      "     Support from lecturers     0.5751    0.6744    0.6208       857\n",
      "           Teaching quality     0.7376    0.7644    0.7508      1269\n",
      "        Test and evaluation     0.5759    0.7000    0.6319       130\n",
      "                   Workload     0.5529    0.6647    0.6037       173\n",
      "\n",
      "                  micro avg     0.5948    0.6957    0.6413      3473\n",
      "                  macro avg     0.5749    0.6750    0.6183      3473\n",
      "               weighted avg     0.6132    0.6957    0.6496      3473\n",
      "                samples avg     0.6054    0.7006    0.6300      3473\n",
      "\n",
      "--- Kết thúc ACD ---\n",
      "\n",
      "==================== Tác vụ 2: Sentiment Polarity Classification (SPC) ====================\n",
      "Số lượng Polarity duy nhất: 3\n",
      "\n",
      "--- Bắt đầu SPC ---\n",
      "  Bắt đầu huấn luyện...\n",
      "  Huấn luyện hoàn tất.\n",
      "  Bắt đầu dự đoán...\n",
      "  Dự đoán hoàn tất.\n",
      "\n",
      "  --- Kết quả đánh giá ---\n",
      "  Hamming Loss: 0.1136\n",
      "  Subset Accuracy: 0.7693\n",
      "\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.8312    0.8841    0.8569       975\n",
      "     neutral     0.5319    0.7356    0.6174       522\n",
      "    positive     0.9347    0.8884    0.9110      1693\n",
      "\n",
      "   micro avg     0.8165    0.8621    0.8387      3190\n",
      "   macro avg     0.7659    0.8360    0.7951      3190\n",
      "weighted avg     0.8372    0.8621    0.8464      3190\n",
      " samples avg     0.8302    0.8686    0.8407      3190\n",
      "\n",
      "--- Kết thúc SPC ---\n",
      "\n",
      "==================== Tác vụ 3: Category#Polarity Pair Detection (ASCA) ====================\n",
      "Số lượng Cặp Category#Polarity duy nhất: 24\n",
      "\n",
      "--- Bắt đầu ASCA Pairs ---\n",
      "  Bắt đầu huấn luyện...\n",
      "  Huấn luyện hoàn tất.\n",
      "  Bắt đầu dự đoán...\n",
      "  Dự đoán hoàn tất.\n",
      "\n",
      "  --- Kết quả đánh giá ---\n",
      "  Hamming Loss: 0.0515\n",
      "  Subset Accuracy: 0.2780\n",
      "\n",
      "  Classification Report:\n",
      "                                      precision    recall  f1-score   support\n",
      "\n",
      "         Course information#negative     0.3315    0.5041    0.4000       121\n",
      "          Course information#neutral     0.2914    0.4444    0.3520        99\n",
      "         Course information#positive     0.3297    0.5217    0.4040       115\n",
      "             General review#negative     0.2179    0.2500    0.2329        68\n",
      "              General review#neutral     0.2366    0.3407    0.2793        91\n",
      "             General review#positive     0.2281    0.4779    0.3088       136\n",
      "       Learning environment#negative     0.5948    0.7419    0.6603        93\n",
      "        Learning environment#neutral     0.5393    0.8276    0.6531        58\n",
      "       Learning environment#positive     0.2000    0.2286    0.2133        35\n",
      "Organization and management#negative     0.4969    0.6400    0.5594       125\n",
      " Organization and management#neutral     0.2442    0.3559    0.2897        59\n",
      "Organization and management#positive     0.4521    0.5323    0.4889        62\n",
      "     Support from lecturers#negative     0.2915    0.5150    0.3723       167\n",
      "      Support from lecturers#neutral     0.1389    0.2128    0.1681        47\n",
      "     Support from lecturers#positive     0.5626    0.7450    0.6411       651\n",
      "           Teaching quality#negative     0.5407    0.7365    0.6236       334\n",
      "            Teaching quality#neutral     0.2956    0.4519    0.3574       104\n",
      "           Teaching quality#positive     0.6943    0.8090    0.7473       848\n",
      "        Test and evaluation#negative     0.4675    0.5070    0.4865        71\n",
      "         Test and evaluation#neutral     0.3158    0.5455    0.4000        33\n",
      "        Test and evaluation#positive     0.2750    0.3793    0.3188        29\n",
      "                   Workload#negative     0.4444    0.4308    0.4375        65\n",
      "                    Workload#neutral     0.3647    0.5536    0.4397        56\n",
      "                   Workload#positive     0.3444    0.5741    0.4306        54\n",
      "\n",
      "                           micro avg     0.4673    0.6396    0.5400      3521\n",
      "                           macro avg     0.3708    0.5136    0.4277      3521\n",
      "                        weighted avg     0.4867    0.6396    0.5501      3521\n",
      "                         samples avg     0.4768    0.6430    0.5235      3521\n",
      "\n",
      "--- Kết thúc ASCA Pairs ---\n",
      "\n",
      "Hoàn thành tất cả các tác vụ.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, hamming_loss, accuracy_score\n",
    "\n",
    "# --- 1. Hàm đọc dữ liệu ASCA JSON (Giữ nguyên) ---\n",
    "def load_asca_data(filepath):\n",
    "    \"\"\"Đọc dữ liệu từ file JSON định dạng ASCA.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            if \"sentences\" in data and isinstance(data[\"sentences\"], list):\n",
    "                return data[\"sentences\"]\n",
    "            else:\n",
    "                print(f\"Lỗi: Cấu trúc JSON không đúng trong file {filepath}.\")\n",
    "                return []\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Lỗi: Không tìm thấy file {filepath}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Lỗi: File {filepath} không phải là định dạng JSON hợp lệ.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi đọc file: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- 2. Hàm huấn luyện và đánh giá mô hình đa nhãn (Giữ nguyên) ---\n",
    "def train_evaluate_multilabel(X_train, y_train, X_test, y_test, labels_list, task_name=\"\"):\n",
    "    \"\"\"Huấn luyện và đánh giá mô hình đa nhãn (TF-IDF + OneVsRest).\"\"\"\n",
    "    print(f\"\\n--- Bắt đầu {task_name} ---\")\n",
    "\n",
    "    # Lựa chọn base classifier\n",
    "    # base_classifier = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
    "    base_classifier = LinearSVC(random_state=42, dual=\"auto\", class_weight='balanced')\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(min_df=3, max_df=0.9, ngram_range=(1, 2))),\n",
    "        ('clf', OneVsRestClassifier(base_classifier, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "    print(\"  Bắt đầu huấn luyện...\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"  Huấn luyện hoàn tất.\")\n",
    "\n",
    "    print(\"  Bắt đầu dự đoán...\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"  Dự đoán hoàn tất.\")\n",
    "\n",
    "    print(\"\\n  --- Kết quả đánh giá ---\")\n",
    "    h_loss = hamming_loss(y_test, y_pred)\n",
    "    subset_acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"  Hamming Loss: {h_loss:.4f}\")\n",
    "    print(f\"  Subset Accuracy: {subset_acc:.4f}\")\n",
    "\n",
    "    print(\"\\n  Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        labels=np.arange(len(labels_list)), # Cung cấp chỉ số của các lớp\n",
    "        target_names=labels_list,          # Tên tương ứng của các lớp\n",
    "        zero_division=0,\n",
    "        digits=4\n",
    "    )\n",
    "    print(report)\n",
    "    print(f\"--- Kết thúc {task_name} ---\")\n",
    "    return pipeline \n",
    "\n",
    "\n",
    "input_json_file = 'output_asca_format_corrected.json'\n",
    "raw_data = load_asca_data(input_json_file)\n",
    "\n",
    "if not raw_data:\n",
    "    print(\"Không có dữ liệu để xử lý.\")\n",
    "else:\n",
    "    print(f\"Đã đọc {len(raw_data)} câu từ file JSON.\")\n",
    "    X_texts = [item['text'] for item in raw_data]\n",
    "    y_categories_raw = [\n",
    "        list(set(cat_pol['category'] for cat_pol in item.get('aspectCategories', []) if cat_pol.get('category')))\n",
    "        for item in raw_data\n",
    "    ]\n",
    "    mlb_category = MultiLabelBinarizer()\n",
    "    y_categories_binarized = mlb_category.fit_transform(y_categories_raw)\n",
    "    category_labels = mlb_category.classes_\n",
    "    y_polarities_raw = [\n",
    "        list(set(cat_pol['polarity'] for cat_pol in item.get('aspectCategories', []) if cat_pol.get('polarity')))\n",
    "        for item in raw_data\n",
    "    ]\n",
    "    mlb_polarity = MultiLabelBinarizer()\n",
    "    y_polarities_binarized = mlb_polarity.fit_transform(y_polarities_raw)\n",
    "    polarity_labels = sorted([p for p in ['positive', 'negative', 'neutral'] if p in mlb_polarity.classes_])\n",
    "    y_catpol_raw = [\n",
    "        [f\"{cat_pol['category']}#{cat_pol['polarity']}\"\n",
    "         for cat_pol in item.get('aspectCategories', []) if cat_pol.get('category') and cat_pol.get('polarity')]\n",
    "        for item in raw_data\n",
    "    ]\n",
    "    mlb_catpol = MultiLabelBinarizer()\n",
    "    y_catpol_binarized = mlb_catpol.fit_transform(y_catpol_raw)\n",
    "    catpol_labels = mlb_catpol.classes_\n",
    "    indices = np.arange(len(X_texts))\n",
    "    X_train_texts, X_test_texts, y_train_cat, y_test_cat, y_train_pol, y_test_pol, y_train_cp, y_test_cp, train_indices, test_indices = train_test_split(\n",
    "        X_texts,\n",
    "        y_categories_binarized,\n",
    "        y_polarities_binarized,\n",
    "        y_catpol_binarized,\n",
    "        indices,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Tổng số mẫu: {len(X_texts)}\")\n",
    "    print(f\"Kích thước tập huấn luyện: {len(X_train_texts)}\")\n",
    "    print(f\"Kích thước tập kiểm thử: {len(X_test_texts)}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \" Tác vụ 1: Aspect Category Detection (ACD) \" + \"=\"*20)\n",
    "    print(f\"Số lượng Category duy nhất: {len(category_labels)}\")\n",
    "    pipeline_acd = train_evaluate_multilabel(X_train_texts, y_train_cat, X_test_texts, y_test_cat, category_labels, \"ACD\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \" Tác vụ 2: Sentiment Polarity Classification (SPC) \" + \"=\"*20)\n",
    "    print(f\"Số lượng Polarity duy nhất: {len(polarity_labels)}\")\n",
    "    pipeline_spc = train_evaluate_multilabel(X_train_texts, y_train_pol, X_test_texts, y_test_pol, polarity_labels, \"SPC\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*20 + \" Tác vụ 3: Category#Polarity Pair Detection (ASCA) \" + \"=\"*20)\n",
    "    print(f\"Số lượng Cặp Category#Polarity duy nhất: {len(catpol_labels)}\")\n",
    "    pipeline_catpol = train_evaluate_multilabel(X_train_texts, y_train_cp, X_test_texts, y_test_cp, catpol_labels, \"ASCA Pairs\")\n",
    "\n",
    "\n",
    "    print(\"\\nHoàn thành tất cả các tác vụ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tải dữ liệu thành công.\n",
      "\n",
      "Số lượng dòng sau khi xóa NaN: 20779\n",
      "\n",
      "Số lượng mẫu huấn luyện: 16623\n",
      "Số lượng mẫu kiểm thử: 4156\n",
      "\n",
      "--- Huấn luyện & Đánh giá Mô hình Nhận diện Aspect ---\n",
      "Đang huấn luyện mô hình Aspect...\n",
      "Dự đoán Aspect trên tập kiểm thử (test_df)...\n",
      "Độ chính xác (Accuracy) riêng cho Aspect: 0.6939\n",
      "\n",
      "Báo cáo phân loại chi tiết cho Aspect:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "         Course information     0.5936    0.7146    0.6485       417\n",
      "             General review     0.4549    0.4242    0.4390       297\n",
      "       Learning environment     0.7795    0.8879    0.8302       223\n",
      "Organization and management     0.6176    0.7243    0.6667       301\n",
      "     Support from lecturers     0.7285    0.6753    0.7009      1152\n",
      "           Teaching quality     0.7753    0.7113    0.7419      1455\n",
      "        Test and evaluation     0.6541    0.7591    0.7027       137\n",
      "                   Workload     0.6106    0.7299    0.6649       174\n",
      "\n",
      "                   accuracy                         0.6939      4156\n",
      "                  macro avg     0.6518    0.7033    0.6744      4156\n",
      "               weighted avg     0.6991    0.6939    0.6943      4156\n",
      "\n",
      "\n",
      "--- Huấn luyện & Đánh giá Mô hình Phân loại Sentiment ---\n",
      "Đang huấn luyện mô hình Sentiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duycute/.pyenv/versions/3.11.11/envs/Ai_ENV/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán Sentiment trên tập kiểm thử (test_df)...\n",
      "Độ chính xác (Accuracy) riêng cho Sentiment: 0.8590\n",
      "\n",
      "Báo cáo phân loại chi tiết cho Sentiment:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.8407    0.8681    0.8542      1198\n",
      "     Neutral     0.7143    0.5693    0.6336       606\n",
      "    Positive     0.8970    0.9290    0.9127      2352\n",
      "\n",
      "    accuracy                         0.8590      4156\n",
      "   macro avg     0.8173    0.7888    0.8002      4156\n",
      "weighted avg     0.8541    0.8590    0.8551      4156\n",
      "\n",
      "\n",
      "--- Đánh giá hiệu suất dự đoán CẶP {Aspect: Sentiment} ---\n",
      "Độ chính xác (Accuracy) cho việc dự đoán đúng cả cặp {Aspect: Sentiment}: 0.6011\n",
      "F1-score (Weighted) cho việc dự đoán đúng cả cặp {Aspect: Sentiment}: 0.6022\n",
      "F1-score (Macro)   cho việc dự đoán đúng cả cặp {Aspect: Sentiment}: 0.4881\n",
      "\n",
      "Báo cáo phân loại chi tiết cho từng cặp {Aspect: Sentiment}:\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "         {Course information: Negative}     0.5114    0.5806    0.5438       155\n",
      "          {Course information: Neutral}     0.3893    0.4080    0.3984       125\n",
      "         {Course information: Positive}     0.4051    0.5766    0.4759       137\n",
      "             {General review: Negative}     0.1807    0.2830    0.2206        53\n",
      "              {General review: Neutral}     0.4615    0.1304    0.2034        92\n",
      "             {General review: Positive}     0.3571    0.3947    0.3750       152\n",
      "       {Learning environment: Negative}     0.8537    0.7955    0.8235       132\n",
      "        {Learning environment: Neutral}     0.5614    0.6531    0.6038        49\n",
      "       {Learning environment: Positive}     0.2432    0.4286    0.3103        42\n",
      "{Organization and management: Negative}     0.5838    0.6918    0.6332       146\n",
      " {Organization and management: Neutral}     0.4348    0.3704    0.4000        81\n",
      "{Organization and management: Positive}     0.4865    0.7297    0.5838        74\n",
      "     {Support from lecturers: Negative}     0.5784    0.4908    0.5310       218\n",
      "      {Support from lecturers: Neutral}     0.2444    0.2115    0.2268        52\n",
      "     {Support from lecturers: Positive}     0.7315    0.6950    0.7128       882\n",
      "           {Teaching quality: Negative}     0.6686    0.6366    0.6522       355\n",
      "            {Teaching quality: Neutral}     0.4925    0.2895    0.3646       114\n",
      "           {Teaching quality: Positive}     0.7452    0.7028    0.7234       986\n",
      "        {Test and evaluation: Negative}     0.4828    0.6087    0.5385        69\n",
      "         {Test and evaluation: Neutral}     0.5135    0.4419    0.4750        43\n",
      "        {Test and evaluation: Positive}     0.4000    0.5600    0.4667        25\n",
      "                   {Workload: Negative}     0.5000    0.5143    0.5070        70\n",
      "                    {Workload: Neutral}     0.4510    0.4600    0.4554        50\n",
      "                   {Workload: Positive}     0.4000    0.6296    0.4892        54\n",
      "\n",
      "                               accuracy                         0.6011      4156\n",
      "                              macro avg     0.4865    0.5118    0.4881      4156\n",
      "                           weighted avg     0.6144    0.6011    0.6022      4156\n",
      "\n",
      "\n",
      "--- Hiển thị ví dụ Kết quả Dự đoán Cặp {Aspect: Sentiment} trên Tập Kiểm Thử ---\n",
      "(Hiển thị 20 mẫu đầu tiên của tập kiểm thử)\n",
      "                                                                                  Sentence Component                                                      sentiment_text                                true_pair                           predicted_pair\n",
      "19406                                                                                       đúng giờ                                                            đúng giờ  {Organization and management: Positive}  {Organization and management: Positive}\n",
      "2769   và nên cập nhập lên visual 2008 hay 2010 gì đó , vì em thấy một số máy chạy visual 2005 bị lỗ                                                        nên cập nhập   {Organization and management: Neutral}   {Organization and management: Neutral}\n",
      "16186                             không dùng điểm để đánh giá , nó làm sinh viên không dám thực hiện  không dùng điểm để đánh giá , nó làm sinh viên không dám thực hiện          {Test and evaluation: Negative}          {Test and evaluation: Negative}\n",
      "5061                                                          rất hay khuyến khích tinh thần học tập                                                             rất hay       {Support from lecturers: Positive}       {Support from lecturers: Positive}\n",
      "365                                                                               dạy toàn tiếng anh                                                  dạy toàn tiếng anh            {Course information: Neutral}             {Teaching quality: Negative}\n",
      "17605                                      em thật sự không nắm được nội dung và yêu cầu của môn học                                              thật sự không nắm được           {Course information: Negative}           {Course information: Negative}\n",
      "12584                                                        nên đầu tư nhiều hơn vào trang thiết bị                                                          nên đầu tư          {Learning environment: Neutral}          {Learning environment: Neutral}\n",
      "10890                        sự tận tâm , nhiệt tình và truyền đạt kiến thức cần thiết cho sinh viên                                                tận tâm , nhiệt tình             {Teaching quality: Positive}             {Teaching quality: Positive}\n",
      "15796                                                     sau 30 fraction 4 giảng viên không đến lớp                                                       không đến lớp  {Organization and management: Negative}  {Organization and management: Negative}\n",
      "6487                                                                    giọng thầy còn nhỏ , đều đều                                                   còn nhỏ , đều đều               {General review: Negative}             {Teaching quality: Negative}\n",
      "886                                                                     cần cải thiện hệ thống điện                                                        cần cải thiện          {Learning environment: Neutral}          {Learning environment: Neutral}\n",
      "13185                                                           thầy dạy hay , vui vẻ , rất hài lòng                                                              vui vẻ       {Support from lecturers: Positive}             {Teaching quality: Positive}\n",
      "16421                                                                       giảng viên đến đúng giờ                                                             đúng giờ  {Organization and management: Positive}  {Organization and management: Positive}\n",
      "2159                                                                         cần cho ví dụ nhiều hơn                                             cần cho ví dụ nhiều hơn       {Support from lecturers: Positive}              {Teaching quality: Neutral}\n",
      "17848                                              tài liệu học môn này cần được cập nhật đầy đủ hơn                                        cần được cập nhật đầy đủ hơn           {Course information: Positive}           {Course information: Positive}\n",
      "10346                                                                             cô rất vui tính nà                                                     rất vui tính nà             {Teaching quality: Positive}       {Support from lecturers: Positive}\n",
      "4019                nội dung giảng dạy hơi khó hiểu , đi nhanh , sinh viên khó nắm bắt kịp bài giảng                                                        hơi khó hiểu       {Support from lecturers: Negative}       {Support from lecturers: Negative}\n",
      "16034                                                                        giảng viên có tâm huyết                                             giảng viên có tâm huyết               {General review: Positive}       {Support from lecturers: Positive}\n",
      "7791                                        nội dung môn học không đáp ứng được mục tiêu của môn học                                                  không đáp ứng được           {Course information: Negative}           {Course information: Negative}\n",
      "6151                                                                  kết hợp lý thuyết và thực hành                                                             kết hợp            {Course information: Neutral}           {Course information: Positive}\n",
      "\n",
      "--- Kết thúc ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Import đầy đủ các hàm metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import re\n",
    "\n",
    "# --- Configuration ---\n",
    "FILE_PATH = 'combined_cleaned_file.txt' # Đường dẫn tới file dữ liệu của bạn\n",
    "TEST_SIZE = 0.2 # Tỷ lệ dữ liệu dùng để kiểm thử (validation)\n",
    "RANDOM_STATE = 42 # Để đảm bảo kết quả lặp lại được\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    df = pd.read_csv(FILE_PATH, sep='\\t', encoding='utf-8')\n",
    "    print(\"Đã tải dữ liệu thành công.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file tại đường dẫn '{FILE_PATH}'\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi đọc file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Data Cleaning and Preparation ---\n",
    "required_columns = ['Sentence Component', 'aspect', 'sentiment_text', 'sentiment']\n",
    "df.dropna(subset=required_columns, inplace=True)\n",
    "print(f\"\\nSố lượng dòng sau khi xóa NaN: {len(df)}\")\n",
    "\n",
    "# Loại bỏ các ký tự đặc biệt (Tùy chọn)\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'colonsmilesmile|wzjwz\\d+', '', text, flags=re.IGNORECASE)\n",
    "        text = text.strip()\n",
    "    return text\n",
    "# df['Sentence Component'] = df['Sentence Component'].apply(clean_text)\n",
    "# df['sentiment_text'] = df['sentiment_text'].apply(clean_text)\n",
    "\n",
    "# --- Split Data into Training and Testing Sets (Using DataFrame) ---\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=df['aspect'] # Stratify theo aspect\n",
    ")\n",
    "print(f\"\\nSố lượng mẫu huấn luyện: {len(train_df)}\")\n",
    "print(f\"Số lượng mẫu kiểm thử: {len(test_df)}\")\n",
    "\n",
    "\n",
    "# --- 1. Aspect Identification Model ---\n",
    "print(\"\\n--- Huấn luyện & Đánh giá Mô hình Nhận diện Aspect ---\")\n",
    "aspect_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', LinearSVC(random_state=42, dual=\"auto\", class_weight='balanced'))\n",
    "])\n",
    "print(\"Đang huấn luyện mô hình Aspect...\")\n",
    "aspect_pipeline.fit(train_df['Sentence Component'] + train_df['Review'], train_df['aspect'])\n",
    "print(\"Dự đoán Aspect trên tập kiểm thử (test_df)...\")\n",
    "predicted_aspects = aspect_pipeline.predict(test_df['Sentence Component'])\n",
    "test_df['predicted_aspect'] = predicted_aspects\n",
    "accuracy_aspect = accuracy_score(test_df['aspect'], test_df['predicted_aspect'])\n",
    "print(f\"Độ chính xác (Accuracy) riêng cho Aspect: {accuracy_aspect:.4f}\")\n",
    "\n",
    "# --- Hiển thị lại Classification Report cho Aspect ---\n",
    "print(\"\\nBáo cáo phân loại chi tiết cho Aspect:\")\n",
    "# Lấy danh sách các nhãn aspect duy nhất từ cả tập thực tế và dự đoán\n",
    "all_aspect_labels = sorted(list(set(test_df['aspect']) | set(test_df['predicted_aspect'])))\n",
    "# In báo cáo\n",
    "print(classification_report(test_df['aspect'], test_df['predicted_aspect'], labels=all_aspect_labels, zero_division=0, digits=4))\n",
    "# --- Kết thúc phần hiển thị lại ---\n",
    "\n",
    "\n",
    "# --- 2. Sentiment Classification Model ---\n",
    "print(\"\\n--- Huấn luyện & Đánh giá Mô hình Phân loại Sentiment ---\")\n",
    "sentiment_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('clf', LogisticRegression(solver='liblinear', multi_class='auto', random_state=RANDOM_STATE))\n",
    "])\n",
    "print(\"Đang huấn luyện mô hình Sentiment...\")\n",
    "sentiment_pipeline.fit(train_df['sentiment_text'] + train_df['Review'], train_df['sentiment'])\n",
    "print(\"Dự đoán Sentiment trên tập kiểm thử (test_df)...\")\n",
    "predicted_sentiments = sentiment_pipeline.predict(test_df['sentiment_text'])\n",
    "test_df['predicted_sentiment'] = predicted_sentiments\n",
    "accuracy_sentiment = accuracy_score(test_df['sentiment'], test_df['predicted_sentiment'])\n",
    "print(f\"Độ chính xác (Accuracy) riêng cho Sentiment: {accuracy_sentiment:.4f}\")\n",
    "\n",
    "# --- Hiển thị lại Classification Report cho Sentiment ---\n",
    "print(\"\\nBáo cáo phân loại chi tiết cho Sentiment:\")\n",
    "# Lấy danh sách các nhãn sentiment duy nhất từ cả tập thực tế và dự đoán\n",
    "all_sentiment_labels = sorted(list(set(test_df['sentiment']) | set(test_df['predicted_sentiment'])))\n",
    "# In báo cáo\n",
    "print(classification_report(test_df['sentiment'], test_df['predicted_sentiment'], labels=all_sentiment_labels, zero_division=0, digits=4))\n",
    "# --- Kết thúc phần hiển thị lại ---\n",
    "\n",
    "\n",
    "# --- 3. Combine Predictions and Evaluate Pair Performance ---\n",
    "print(\"\\n--- Đánh giá hiệu suất dự đoán CẶP {Aspect: Sentiment} ---\")\n",
    "\n",
    "test_df['true_pair'] = test_df.apply(lambda row: f\"{{{row['aspect']}: {row['sentiment']}}}\", axis=1)\n",
    "test_df['predicted_pair'] = test_df.apply(lambda row: f\"{{{row['predicted_aspect']}: {row['predicted_sentiment']}}}\", axis=1)\n",
    "\n",
    "pair_accuracy = accuracy_score(test_df['true_pair'], test_df['predicted_pair'])\n",
    "print(f\"Độ chính xác (Accuracy) cho việc dự đoán đúng cả cặp {{Aspect: Sentiment}}: {pair_accuracy:.4f}\")\n",
    "\n",
    "pair_f1_weighted = f1_score(test_df['true_pair'], test_df['predicted_pair'], average='weighted', zero_division=0)\n",
    "pair_f1_macro = f1_score(test_df['true_pair'], test_df['predicted_pair'], average='macro', zero_division=0)\n",
    "print(f\"F1-score (Weighted) cho việc dự đoán đúng cả cặp {{Aspect: Sentiment}}: {pair_f1_weighted:.4f}\")\n",
    "print(f\"F1-score (Macro)   cho việc dự đoán đúng cả cặp {{Aspect: Sentiment}}: {pair_f1_macro:.4f}\")\n",
    "\n",
    "print(\"\\nBáo cáo phân loại chi tiết cho từng cặp {Aspect: Sentiment}:\")\n",
    "all_pair_labels = sorted(list(set(test_df['true_pair']) | set(test_df['predicted_pair'])))\n",
    "print(classification_report(test_df['true_pair'], test_df['predicted_pair'], labels=all_pair_labels, zero_division=0, digits=4))\n",
    "\n",
    "\n",
    "# --- 4. Display Predicted Aspect:Sentiment Pairs for Test Set (Example) ---\n",
    "print(\"\\n--- Hiển thị ví dụ Kết quả Dự đoán Cặp {Aspect: Sentiment} trên Tập Kiểm Thử ---\")\n",
    "print(\"(Hiển thị 20 mẫu đầu tiên của tập kiểm thử)\")\n",
    "\n",
    "columns_to_show = [\n",
    "    'Sentence Component',\n",
    "    'sentiment_text',\n",
    "    'true_pair',\n",
    "    'predicted_pair'\n",
    "]\n",
    "print(test_df[columns_to_show].head(20).to_string())\n",
    "\n",
    "print(\"\\n--- Kết thúc ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15519 sentences.\n",
      "Processing sentences and extracting features...\n",
      "Processed 15519 sentences successfully.\n",
      "\n",
      "Train size: 11639\n",
      "Test size: 3880\n",
      "\n",
      "Initializing and training CRF model...\n",
      "Training complete.\n",
      "\n",
      "Evaluating model on test set...\n",
      "\n",
      "Flat Classification Report (excluding 'O'):\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "         B-Course_information      0.542     0.379     0.446       428\n",
      "         I-Course_information      0.270     0.274     0.272       862\n",
      "             B-General_review      0.349     0.202     0.256       361\n",
      "             I-General_review      0.173     0.197     0.184      1398\n",
      "       B-Learning_environment      0.741     0.564     0.640       243\n",
      "       I-Learning_environment      0.621     0.438     0.513       592\n",
      "B-Organization_and_management      0.367     0.238     0.289       340\n",
      "I-Organization_and_management      0.367     0.224     0.278      1595\n",
      "     B-Support_from_lecturers      0.428     0.282     0.340      1143\n",
      "     I-Support_from_lecturers      0.378     0.322     0.348      2534\n",
      "           B-Teaching_quality      0.519     0.459     0.487      1749\n",
      "           I-Teaching_quality      0.297     0.219     0.252      3015\n",
      "        B-Test_and_evaluation      0.545     0.325     0.407       169\n",
      "        I-Test_and_evaluation      0.362     0.169     0.231       544\n",
      "                   B-Workload      0.517     0.404     0.453       228\n",
      "                   I-Workload      0.358     0.223     0.275       364\n",
      "\n",
      "                    micro avg      0.369     0.289     0.324     15565\n",
      "                    macro avg      0.427     0.307     0.354     15565\n",
      "                 weighted avg      0.378     0.289     0.325     15565\n",
      "\n",
      "\n",
      "Đã lưu mô hình CRF vào file: sklearn_crf_aspect_extractor.joblib\n",
      "\n",
      "--- Ví dụ dự đoán Aspect ---\n",
      "Câu: giáo viên nhiệt tình nhưng cơ sở vật chất cần cải thiện .\n",
      "Tokens: ['giáo viên', 'nhiệt tình', 'nhưng', 'cơ sở vật chất', 'cần', 'cải thiện', '.']\n",
      "Predicted BIO Tags: ['B-Support_from_lecturers', 'O', 'O', 'B-Learning_environment', 'O', 'O', 'O']\n",
      "Extracted Aspects: [{'term': 'giáo viên', 'category': 'Support_from_lecturers'}, {'term': 'cơ sở vật chất', 'category': 'Learning_environment'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import underthesea # For Vietnamese word tokenization\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import joblib\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Loads data from the JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        # Adjust based on the actual structure\n",
    "        if \"sentences\" in data and \"sentence\" in data[\"sentences\"]:\n",
    "             return data[\"sentences\"][\"sentence\"]\n",
    "        elif isinstance(data, list): # Handle if data is directly a list of sentences\n",
    "             return data\n",
    "        else:\n",
    "             raise ValueError(\"Cannot find sentence list in the JSON structure\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {filepath}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not decode JSON from {filepath}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred loading data: {e}\")\n",
    "        return []\n",
    "\n",
    "# --- 2. Data Preparation ---\n",
    "\n",
    "def word_tokenize(sentence):\n",
    "  \"\"\"Tokenizes a Vietnamese sentence.\"\"\"\n",
    "  # return sentence.split() # Simple whitespace split (less accurate)\n",
    "  return underthesea.word_tokenize(sentence)\n",
    "\n",
    "def get_bio_tags(tokens, aspects):\n",
    "    \"\"\"\n",
    "    Generates BIO tags for a tokenized sentence based on aspect spans.\n",
    "    Assumes non-overlapping aspects. Encodes category in the tag.\n",
    "    \"\"\"\n",
    "    tags = ['O'] * len(tokens)\n",
    "    token_spans = []\n",
    "    current_pos = 0\n",
    "    # Calculate character spans for each token\n",
    "    for token in tokens:\n",
    "        start = current_pos\n",
    "        end = start + len(token)\n",
    "        token_spans.append((start, end))\n",
    "        # Assuming space separation after tokenization for simplicity\n",
    "        current_pos = end + 1 # Move past the token and the assumed space\n",
    "\n",
    "    for aspect in aspects:\n",
    "        try:\n",
    "            aspect_start = int(aspect['from'])\n",
    "            aspect_end = int(aspect['to']) # Assumes exclusive\n",
    "            category = aspect['category'].strip().replace(\" \", \"_\") # Sanitize category name\n",
    "            if not category: continue\n",
    "\n",
    "            b_tag = f\"B-{category}\"\n",
    "            i_tag = f\"I-{category}\"\n",
    "            first_token_in_span = True\n",
    "\n",
    "            for i, (tok_start, tok_end) in enumerate(token_spans):\n",
    "                 # Check if token overlaps with the aspect span\n",
    "                 # A simple overlap check: token starts within aspect OR aspect starts within token\n",
    "                token_overlaps = (tok_start >= aspect_start and tok_start < aspect_end) or \\\n",
    "                                 (aspect_start >= tok_start and aspect_start < tok_end)\n",
    "\n",
    "                if token_overlaps:\n",
    "                     # Ensure we don't overwrite tags from other aspects (shouldn't happen with no_overlap file)\n",
    "                    if tags[i] == 'O':\n",
    "                        if first_token_in_span:\n",
    "                            tags[i] = b_tag\n",
    "                            first_token_in_span = False\n",
    "                        else:\n",
    "                            tags[i] = i_tag\n",
    "        except (ValueError, KeyError) as e:\n",
    "            print(f\"Warning: Skipping aspect due to data issue: {aspect}. Error: {e}\")\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "# --- 3. Feature Extraction ---\n",
    "\n",
    "def word2features(sent, i):\n",
    "    \"\"\"Extracts features for a word at position i in the sentence (list of tokens).\"\"\"\n",
    "    word = sent[i]\n",
    "    # Add more features here for better performance!\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        # You can add prefix/suffix features:\n",
    "        'word.suffix(3)': word[-3:],\n",
    "        'word.prefix(3)': word[:3],\n",
    "         # Add shape features (e.g., 'Xxxx', 'dd'):\n",
    "        'word.shape': ''.join(['X' if c.isupper() else 'x' if c.islower() else 'd' if c.isdigit() else c for c in word]),\n",
    "\n",
    "    }\n",
    "    # Features for previous word (if not beginning of sentence)\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True # Indicate Beginning Of Sentence\n",
    "\n",
    "    # Features for next word (if not end of sentence)\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True # Indicate End Of Sentence\n",
    "\n",
    "    # --- Potential improvements (require more libraries/effort): ---\n",
    "    # - Part-of-Speech (POS) tags for current, previous, next words\n",
    "    # - Word embedding features (e.g., from PhoBERT, Word2Vec)\n",
    "    # - Gazetteer features (is the word in a predefined list of locations, names, etc.?)\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    \"\"\"Applies word2features to each word in the sentence.\"\"\"\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(tags):\n",
    "    \"\"\"Returns the list of labels (already prepared).\"\"\"\n",
    "    return tags\n",
    "\n",
    "# --- Main Data Processing ---\n",
    "\n",
    "input_file = 'output_semeval_format_v3_no_overlap.txt'\n",
    "raw_data = load_data(input_file)\n",
    "\n",
    "if not raw_data:\n",
    "    print(\"Exiting due to data loading errors.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loaded {len(raw_data)} sentences.\")\n",
    "\n",
    "# Process all sentences\n",
    "X = [] # List of feature dict sequences for sentences\n",
    "y = [] # List of label sequences for sentences\n",
    "\n",
    "print(\"Processing sentences and extracting features...\")\n",
    "for sentence_data in raw_data:\n",
    "    if 'text' not in sentence_data or 'aspects' not in sentence_data:\n",
    "        continue\n",
    "    text = sentence_data['text']\n",
    "    aspects = sentence_data['aspects']\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    if not tokens: # Skip empty sentences after tokenization\n",
    "         continue\n",
    "\n",
    "    tags = get_bio_tags(tokens, aspects)\n",
    "    features = sent2features(tokens)\n",
    "\n",
    "    # Ensure features and tags have the same length\n",
    "    if len(features) == len(tags):\n",
    "        X.append(features)\n",
    "        y.append(tags)\n",
    "    else:\n",
    "        print(f\"Warning: Mismatch length between features ({len(features)}) and tags ({len(tags)}) for sentence: '{text}'. Skipping.\")\n",
    "\n",
    "\n",
    "print(f\"Processed {len(X)} sentences successfully.\")\n",
    "\n",
    "if not X or not y:\n",
    "     print(\"No data available for training after processing. Exiting.\")\n",
    "     exit()\n",
    "\n",
    "# --- 4. Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"\\nTrain size: {len(X_train)}\")\n",
    "print(f\"Test size: {len(X_test)}\")\n",
    "\n",
    "# --- 5. Initialize and Train CRF Model ---\n",
    "print(\"\\nInitializing and training CRF model...\")\n",
    "\n",
    "# Define CRF model with hyperparameters\n",
    "# You might need to tune these hyperparameters (c1, c2) using cross-validation\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', # Limited-memory Broyden–Fletcher–Goldfarb–Shanno algorithm\n",
    "    c1=0.1,            # Coefficient for L1 penalty\n",
    "    c2=0.1,            # Coefficient for L2 penalty\n",
    "    max_iterations=100,# Stop fitting after some iterations\n",
    "    all_possible_transitions=True # Generate transitions for all label pairs\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    crf.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n",
    "    # Potentially print shapes or first elements of X_train/y_train for debugging\n",
    "    # print(\"X_train[0]:\", X_train[0] if X_train else \"Empty\")\n",
    "    # print(\"y_train[0]:\", y_train[0] if y_train else \"Empty\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 6. Evaluation ---\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "\n",
    "# Get all unique labels, excluding 'O' for aggregated metrics if needed\n",
    "labels = list(crf.classes_)\n",
    "# print(\"Model Classes (Labels):\", labels)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# Calculate metrics (Precision, Recall, F1)\n",
    "# Use flat_classification_report for sequence labeling tasks\n",
    "# Filter out 'O' tag for a more meaningful F1 score for aspect terms\n",
    "sorted_labels = sorted(\n",
    "    [label for label in labels if label != 'O'],\n",
    "    key=lambda name: (name[1:], name[0]) # Sort primarily by category name, then by B/I\n",
    ")\n",
    "\n",
    "try:\n",
    "    report = metrics.flat_classification_report(\n",
    "        y_test, y_pred, labels=sorted_labels, digits=3\n",
    "    )\n",
    "    print(\"\\nFlat Classification Report (excluding 'O'):\")\n",
    "    print(report)\n",
    "except Exception as e:\n",
    "     print(f\"Error generating classification report: {e}\")\n",
    "     # Fallback or print raw predictions/labels for debugging\n",
    "     # print(\"Sample True Labels:\", y_test[0] if y_test else \"N/A\")\n",
    "     # print(\"Sample Predicted Labels:\", y_pred[0] if y_pred else \"N/A\")\n",
    "\n",
    "\n",
    "# --- 7. Save the Model (Optional) ---\n",
    "model_filename_crf = 'sklearn_crf_aspect_extractor.joblib'\n",
    "joblib.dump(crf, model_filename_crf)\n",
    "print(f\"\\nĐã lưu mô hình CRF vào file: {model_filename_crf}\")\n",
    "\n",
    "\n",
    "# --- 8. Prediction Example ---\n",
    "# Load model: loaded_crf = joblib.load(model_filename_crf)\n",
    "\n",
    "print(\"\\n--- Ví dụ dự đoán Aspect ---\")\n",
    "test_sentence = \"giáo viên nhiệt tình nhưng cơ sở vật chất cần cải thiện .\"\n",
    "test_tokens = word_tokenize(test_sentence)\n",
    "test_features = sent2features(test_tokens)\n",
    "\n",
    "predicted_tags = crf.predict_single(test_features)\n",
    "\n",
    "print(f\"Câu: {test_sentence}\")\n",
    "print(\"Tokens:\", test_tokens)\n",
    "print(\"Predicted BIO Tags:\", predicted_tags)\n",
    "\n",
    "# Optional: Group tags into spans\n",
    "def group_tags(tokens, tags):\n",
    "    extracted_aspects = []\n",
    "    current_aspect_tokens = []\n",
    "    current_aspect_type = None\n",
    "    for token, tag in zip(tokens, tags):\n",
    "        if tag.startswith(\"B-\"):\n",
    "            if current_aspect_tokens: # Finish previous aspect\n",
    "                extracted_aspects.append({\"term\": \" \".join(current_aspect_tokens), \"category\": current_aspect_type})\n",
    "            current_aspect_tokens = [token]\n",
    "            current_aspect_type = tag.split(\"-\", 1)[1]\n",
    "        elif tag.startswith(\"I-\"):\n",
    "            tag_type = tag.split(\"-\", 1)[1]\n",
    "            if current_aspect_tokens and tag_type == current_aspect_type: # Continue current aspect\n",
    "                current_aspect_tokens.append(token)\n",
    "            else: # I- tag without B- or mismatch type - treat as O or reset\n",
    "                 if current_aspect_tokens: # Finish previous aspect\n",
    "                      extracted_aspects.append({\"term\": \" \".join(current_aspect_tokens), \"category\": current_aspect_type})\n",
    "                 current_aspect_tokens = []\n",
    "                 current_aspect_type = None\n",
    "        else: # 'O' tag\n",
    "            if current_aspect_tokens: # Finish previous aspect\n",
    "                extracted_aspects.append({\"term\": \" \".join(current_aspect_tokens), \"category\": current_aspect_type})\n",
    "            current_aspect_tokens = []\n",
    "            current_aspect_type = None\n",
    "    # Add the last aspect if any\n",
    "    if current_aspect_tokens:\n",
    "        extracted_aspects.append({\"term\": \" \".join(current_aspect_tokens), \"category\": current_aspect_type})\n",
    "    return extracted_aspects\n",
    "\n",
    "extracted = group_tags(test_tokens, predicted_tags)\n",
    "print(\"Extracted Aspects:\", extracted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
